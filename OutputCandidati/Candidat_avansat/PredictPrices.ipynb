{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Solution for the Predict Prices task",
   "id": "c6b830431a02123b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task 1: Load the dataset and calculate the average price and estimated owners, and output to a file named output_1.csv",
   "id": "45b5b6003c3c481b"
  },
  {
   "cell_type": "code",
   "id": "48f34d0d52e40143",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T17:31:27.067807Z",
     "start_time": "2025-02-06T17:31:26.954225Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from typing import Any, Tuple\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import csv \n",
    "import joblib\n",
    "from dateutil import parser\n",
    "\n",
    "# This function loads the dataset from the given path and returns the features and target variables, as well as the average price, estimated owners, and unique genres\n",
    "# During evaluation set, the is_eval_dataset flag should be set to True, and the known_genres should be passed as a parameter to ensure the same one-hot encoding is used\n",
    "def load_data(dataset_path: str, is_eval_dataset=False, known_genres=None) -> Tuple[Any, Any, int, int, set]:\n",
    "    # Remove columns which you consider not relevant for price prediction\n",
    "    columns_to_drop = [\"AppID\", \"Name\", \"Recommendations\", \"Publishers\"]\n",
    "    \n",
    "    avg_price = 0\n",
    "    avg_owners = 0\n",
    "    \n",
    "    # Note that to do a one-hot encoding, we need to know all possible genres\n",
    "    # First pass will get all genres, then we will create the one-hot encoding\n",
    "    unique_genres = set() if known_genres is None else known_genres\n",
    "\n",
    "    # Load dataset from CSV file\n",
    "    dataset = []\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            # First, remove columns that are not relevant for price prediction\n",
    "            for col in columns_to_drop:\n",
    "                row.pop(col)\n",
    "                \n",
    "            # Extract release year from release_date, since it is more relevant for price prediction\n",
    "            row[\"Release date\"] = parser.parse(row[\"Release date\"]).year\n",
    "            dataset.append(row)\n",
    "\n",
    "            # Add genres to unique_genres set            \n",
    "            genres = row[\"Genres\"].split(\",\") if row[\"Genres\"] else []\n",
    "            unique_genres.update(genres)\n",
    "            \n",
    "            # Convert Estimated owners to numerical range\n",
    "            owners_range = row[\"Estimated owners\"].split(\"-\")\n",
    "            row[\"Estimated owners\"] = int((int(owners_range[0]) + int(owners_range[1])) / 2) if \"-\" in row[\"Estimated owners\"] else int(owners_range[0])\n",
    "            \n",
    "            # Add price and owners to average\n",
    "            if not is_eval_dataset:\n",
    "                avg_price += float(row[\"Price\"])                \n",
    "            avg_owners += row[\"Estimated owners\"]\n",
    "            \n",
    "    # Calculate average price and owners\n",
    "    avg_price = int(avg_price / len(dataset))\n",
    "    avg_owners = int(avg_owners / len(dataset))\n",
    "            \n",
    "    # Create one-hot encoding for genres and merge with original row\n",
    "    for row in dataset:\n",
    "        genres = row[\"Genres\"].split(\",\") if row[\"Genres\"] else []\n",
    "        for genre in unique_genres:\n",
    "            row[genre] = 1 if genre in genres else 0\n",
    "        row.pop(\"Genres\")\n",
    "\n",
    "    \n",
    "    target = \"Price\"\n",
    "    # Separate features (X) and target (y)\n",
    "    X = []\n",
    "    y = []    \n",
    "    \n",
    "    for row in dataset:\n",
    "        features = {} \n",
    "        for key in row:\n",
    "            if key != target:\n",
    "                features[key] = row[key]\n",
    "        X.append(features)\n",
    "        y.append(row[target] if not is_eval_dataset else 0)\n",
    "\n",
    "    # Return the output tuple        \n",
    "    return X, y, avg_price, avg_owners, unique_genres\n",
    "\n",
    "# Load the full dataset\n",
    "X, y, avg_price, avg_owners, unique_genres = load_data(\"../dataset_train.csv\")\n",
    "\n",
    "# Output to a file named output_1.csv the number of samples, the average price and the average owners\n",
    "with open(\"output_1.csv\", \"w\") as file:\n",
    "    # Write the header with the required columns: number of samples, Average Price, Average Owners, and number of unique Genres\n",
    "    file.write(\"Samples,Average Price,Average Owners,Unique Genres\\n\")\n",
    "    # Write the data\n",
    "    file.write(f\"{len(X)},{avg_price},{avg_owners},{len(unique_genres)}\\n\")\n"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train your model - Play as you like from here to get the best AI model ####",
   "id": "6395a4a12726a54c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T17:31:28.971791Z",
     "start_time": "2025-02-06T17:31:27.848971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the dataset to a pandas DataFrame for easier manipulation in other libraries\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y).ravel()\n",
    "\n",
    "# Returns the model trained on the given features and target variables\n",
    "def train_model(X: pd.DataFrame, y: pd.DataFrame) -> Any:\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evaluate the model on your test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the mean absolute error\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Call model training and saving. This will save the model to a file named trained_model.pkl\n",
    "trained_model = train_model(X, y)\n",
    "joblib.dump(trained_model, \"Output_CandidatX/trained_model.pkl\")\n",
    "\n"
   ],
   "id": "672e36b39483434d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 6.6351274999999985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_model.pkl']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task 2: Load the model and the evaluation dataset, and make predictions, and output to a file named output_1.csv",
   "id": "50cc77b429643cf0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T17:31:30.909773Z",
     "start_time": "2025-02-06T17:31:30.806422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_prices(trained_model: Any, dataset_path: str) -> pd.DataFrame:\n",
    "    # Load the model\n",
    "    model = joblib.load(trained_model)\n",
    "    \n",
    "    # Load the evaluation dataset\n",
    "    X_eval, _, _, _, _ = load_data(dataset_path, is_eval_dataset=True, known_genres=unique_genres)\n",
    "    \n",
    "    X_eval = pd.DataFrame(X_eval)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_eval)\n",
    "    \n",
    "    # Save the predictions to a file named output_2.csv with a single column of predictions\n",
    "    # no pandas \n",
    "    with open(\"output_2.csv\", \"w\") as file:\n",
    "        # Write the header\n",
    "        file.write(\"Price\\n\")\n",
    "        # Write the predictions\n",
    "        for pred in y_pred:\n",
    "            file.write(str(pred) + \"\\n\")\n",
    "    \n",
    "    \n",
    "trained_model = joblib.load(\"Output_CandidatX/trained_model.pkl\")\n",
    "predict_prices(\"trained_model.pkl\", \"../dataset_eval.csv\")\n"
   ],
   "id": "1423a41cf6099a81",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "86685c9ec59054ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
